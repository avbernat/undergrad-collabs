Kathmandu_shp<-nepal_shp[nepal_shp$NAME_3 %in% c("Kathmandu", "Bhaktapur", "Lalitpur"),]
plot(Kathmandu_shp)
invisible(text(coordinates(Kathmandu_shp), labels=as.character(Kathmandu_shp$NAME_3)))
#Crop Kathmandu region
PD_kath <- crop(PD, Kathmandu_shp)
## ----histogram-----------------------------------------------------------
# the distribution of values in the raster
hist(PD_kath, main="Distribution of population counts", col= "purple")
## ----plot-raster---------------------------------------------------------
# add a color map with 5 colors
col=topo.colors(5)
# specify the colors using color-ramp
colr <- colorRampPalette(c("navyblue", "steelblue", "limegreen", "yellow", "#FEFEFE"))(255)
# add breaks to the colormap (6 breaks = 5 segments)
brk <- c(0, 5, 10, 35, 100, 1100)
# create a plot of our raster
image(PD_kath, col = col)
# specify the range of values that you want to plot in the PD
# just plot pixels between 0 and 100
image(PD_kath, zlim=c(0,100), col = col, main = "Population Distribution")
#overlay boundary
plot(Kathmandu_shp, add=T, border='white')
#Plot cropped area
plot(PD_kath, main="Population Distribution - Kathmandu", col=colr)
#overlay boundary
plot(Kathmandu_shp, add=T, col=rgb(red=0, blue=0, green=0, alpha=0.1))
## ----plot-with-breaks----------------------------------------------------
plot(PD_kath, col=col, breaks=brk, main="Counts with more breaks", legend = FALSE)
#project raster to 100 meters resolution
#define a projection: https://proj4.org/usage/projections.html
prj<-"+proj=tmerc +lat_0=0 +lon_0=84 +k=0.9996 +x_0=500000 +y_0=0 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0" # this will change it to meters
# UTM = whole globe divided by 6/360 degrees so that way you have 60 "patches"
# other way =
### One single line is sufficient to project any raster to any projection
PD_kath_prj<-projectRaster(PD_kath, crs=crs(prj), res = 100) # 100 m
#multilayer raster example
# Using the previously generated RasterLayer object
r<-PD_kath
# Let's first put some values in the cells of the layer
r[] <- rnorm(n=ncell(r))
# Create a RasterStack object with 3 layers
s <- stack(x=c(r, r*2, r^2))
# The exact same procedure works for creating a RasterBrick
b <- brick(x=c(r, r*2, r))
# Let's look at the properties of of one of these two objects
b
#load raster stack from disk
listras<-list.files(pattern = ".tif$", full.names = T)
listras<-list.files(pattern = ".tif", full.names = T)
#listras<-listras[stringr::str_detect(listras, 'ppp')]
stackras<-stack(listras)
temp_ras <- PD
temp_ras[]<-NA
#load census level 4 data
#pop_sf<-st_read("./NPL_level4/ADMINPOP.shp")
pop_sf<-getData('GADM', country="NEPAL", level=4)
pop_sf$ID_4<-1:nrow(pop_sf)
#much faster using fasterize but requires sf format data
pop_sf<-st_as_sf(pop_sf)
gridz1 <- fasterize::fasterize(pop_sf, temp_ras, field = "ID_4");
compareRaster(gridz, gridz1)
#much faster using fasterize but requires sf format data
pop_sf<-st_as_sf(pop_sf)
gridz1 <- fasterize::fasterize(pop_sf, temp_ras, field = "ID_4");
#Map Algebra Types
#Map algebra can be defined as local, focal, zonal and global operations.
#local operation on raster such change the value if individual cell based on some transformation
logPD<-log10(PD)
#calculate zonal statistics based on zone
zonal_grid <-zonal(PD, gridz, fun = "sum", na.rm = TRUE);
gridz <- fasterize::fasterize(pop_sf, temp_ras, field = "ID_4");
#calculate zonal statistics based on zone
zonal_grid <-zonal(PD, gridz, fun = "sum", na.rm = TRUE);
head(zonal_grid)
#calculate zonal statistics based on zone
zonal_grid <-zonal(PD, gridz, fun = "sum", na.rm = TRUE);
head(zonal_grid)
#focal operation  such as moving average of 3 x 3 cells
focal_grid <- focal(PD, w=matrix(1/9, nc=3, nr=3))
head(focal_grid)
plot(focal_grid)
focal_grid
PD
#global operation such as global sum
cellStats(PD, sum)
cellStats(PD, sd)
for(i in 1:3){print (i)}
for(i in 1:5){print (i)}
125-63
View(m101)
library(faraway)
install.packages("faraway")
library(faraway)
library(tidyverse)
library(tidyverse)
data(gala)
data(gala)
?gala
View(gala)
# Fit a linear model
model <- lm(Species ~ Area + Elevation + Scruz + Nearest + Adjacent, data = gala)
# Make a diagnostic plot
ggplot(data = gala) + geom_point(aes(x = fitted(model), y = residuals(model))) +
geom_hline(yintercept = 0) +
labs(title = "Plot of Fitted Residuals against Fitted Values",
x = "Fitted Values", y = "Fitted Residuals")
library(faraway)
library(tidyverse)
data(gala)
?gala
View(gala)
# Fit a linear model
model <- lm(Species ~ Area + Elevation + Scruz + Nearest + Adjacent, data = gala)
# Make a diagnostic plot
ggplot(data = gala) + geom_point(aes(x = fitted(model), y = residuals(model))) +
geom_hline(yintercept = 0) +
labs(title = "Plot of Fitted Residuals against Fitted Values",
x = "Fitted Values", y = "Fitted Residuals")
data(sat)
?sat
View(sat)
View(sat)
model <- lm(total ~ expend + ratio + salary + takers, data= sat)
# Make a diagnostic plot
ggplot(data = ??) + ??
# Fit a linear model
#model <- lm(??)
model <- lm(total ~ expend + ratio + salary + takers, data= sat)
# Make a diagnostic plot
#ggplot(data = ??) + ??
ggplot(data = sat) + geom_point(aes(x = fitted(model), y = residuals(model))) +
geom_hline(yintercept = 0) +
labs(title = "Plot of Fitted Residuals against Fitted Values",
x = "Fitted Values", y = "Fitted Residuals")
summary(model)
# Print confidence intervals
confint(model,level = 0.95)
df = data.frame(fitted(model))
df
gala["fitted_model"] <- fitted(model)
summary(model)
plot(model)
summary(model)
install.packages("ISLR")
library(ggplot2)
library(dplyr)
library(faraway)
library(gridExtra)
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
data(mtcars)
library(ggplot2)
library(dplyr)
library(faraway)
library(gridExtra)
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
data(mtcars)
# Load the data
library(ISLR)
data(Default)
summary(Default)
str(Default)
# Make some plots of the data that you think are helpful
# in understanding the data
# Convert output to a factor
Default_ <- Default
Default_$default <- as.numeric(Default_$default)-1
# Fit a linear model with student as a response
# and the other variables as predictors
mod.lm <- lm(default ~ student + balance + income, data=Default_)
# Review the output of the model
kable(round(mod.lm$coefficients,2))
# Plot the results of the model
ggplot(data=Default_, aes(x=balance,y=default)) +
geom_point() +
geom_smooth(method="lm")
# Fit the model
binDef <- glm(default ~ student + balance + income,
family=binomial(link="logit"),
data=Default)
# Review the output
kable(round(binDef$coefficients,2))
# Make predictions and plot the result
predDef <- predict(binDef,
type="response") # <-- why do we need this??
Default <- Default %>%
mutate(defaultNum = ifelse(default=="Yes",1,0))
Default <- Default %>%
mutate(predDef = predDef)
pBinDef <- ggplot(data=Default, aes(x=balance, y=defaultNum)) +
geom_point() +
geom_line(data=Default, aes(x=balance, y=predDef, color=Default$student)) +
xlab("Balance") +
ylab("Likelihood of Default") +
labs(title="Probability of Default given Debt Balance") +
guides(color=guide_legend("Student"))
pBinDef
# Fit the model
binDefLarge <- glm(default ~ student * balance * income,
family=binomial(link="logit"),
data=Default)
# Compute difference in deviances and degrees of reedom
diffDev <- binDef$deviance-binDefLarge$deviance
diffDF <- binDef$df.residual - binDefLarge$df.residual
# Difference in deviances
round(diffDev,3)
# p-values
round(1-pchisq(diffDev, diffDF),2)
res1 <- ggplot(data=NULL, aes(x=Default$income, y=residuals(binDef), color=Default$student)) +
geom_point() +
xlab("Income") +
ylab("Deviance Residuals") +
labs(title="Deviance Residuals by Income")
res2<- ggplot(data=NULL, aes(x=Default$student, y=residuals(binDef))) +
geom_boxplot() +
xlab("Student") +
ylab("Deviance Residuals") +
labs(title="Deviance Residuals by Student Type")
res3 <- ggplot(data=NULL, aes(x=Default$balance, y=residuals(binDef), color=Default$student)) +
geom_point() +
xlab("Balance") +
ylab("Deviance Residuals") +
labs(title="Deviance Residuals by Balance")
grid.arrange(res1,res2,res3,
ncol=3)
resHist <- ggplot(data=NULL, aes(x=residuals(binDef))) +
geom_histogram() +
xlab("Residuals") +
ylab("Counts") +
labs(title="Distribution of Deviance Residuals")
resHist
resHist <- ggplot(data=NULL, aes(x=residuals(binDef))) +
geom_histogram() +
xlab("Residuals") +
ylab("Counts") +
labs(title="Distribution of Deviance Residuals")
resHist
qqnorm(residuals(binDef))
halfnorm(hatvalues(binDef))
# Fit the model
binDefLarge <- glm(default ~ student * balance * income,
family=binomial(link="logit"),
data=Default)
# Compute difference in deviances and degrees of reedom
diffDev <- binDef$deviance-binDefLarge$deviance
diffDF <- binDef$df.residual - binDefLarge$df.residual
# Difference in deviances
round(diffDev,3)
# p-values
round(1-pchisq(diffDev, diffDF),2)
rm(list=ls()) # list=ls() is base in this command that means you are referring to all the objects present in the workspace
# some libraries you'll need for the Kruskal-Wallis test
library(tidyverse)
library(ggpubr)
library(rstatix)
library(knitr)
library(ggplot2)
dir = "~/Desktop/git_repositories/undergrad-collabs/voltage_noise/"
setwd(dir)
knitr::opts_chunk$set(echo = TRUE)
data = read_csv("data/allnoise_flight_data-Winter2020.csv")
dir = "~/Desktop/git_repositories/undergrad-collabs/voltage_noise/"
setwd(dir)
rm(list=ls()) # list=ls() is base in this command that means you are referring to all the objects present in the workspace
# some libraries you'll need for the Kruskal-Wallis test
library(tidyverse)
library(ggpubr)
library(rstatix)
library(knitr)
library(ggplot2)
dir = "~/Desktop/git_repositories/undergrad-collabs/voltage_noise/"
setwd(dir)
knitr::opts_chunk$set(echo = TRUE)
```{r}
data = read_csv("data/allnoise_flight_data-Winter2020.csv")
data
data = read_csv("data/allnoise_flight_data-Winter2020.csv")
dir = "~/Desktop/git_repositories/undergrad-collabs/voltage_noise/"
setwd(dir)
getwd()
setwd("~/Desktop/git_repositories/undergrad-collabs/voltage_noise/")
getwd()
data = read_csv("data/allnoise_flight_data-Winter2020.csv")
data
dir = "~/Desktop/git_repositories/undergrad-collabs/voltage_noise/"
setwd(dir)
getwd()
data = read_csv("/data/allnoise_flight_data-Winter2020.csv")
data = read_csv("~/Desktop/git_repositories/undergrad-collabs/voltage_noise/data/allnoise_flight_data-Winter2020.csv")
data
# count
data$tested_b <- 0
data$tested_b[data$tested == "yes"] <- 1
tapply(X=data$tested_b, INDEX=data$chamber, FUN=sum, na.rm=T)
# sum of distances
tapply(X=data$distance, INDEX=data$chamber, FUN=sum, na.rm=T)
# mean of distances
tapply(X=data$distance, INDEX=data$chamber, FUN=mean, na.rm=T)
# count
data$tested_b <- 0
data
data$tested_b[data$tested == "yes"] <- 1
data
# count
#data$tested_b <- 0
data$tested_b[data$tested == "yes"] <- 1
data = read_csv("~/Desktop/git_repositories/undergrad-collabs/voltage_noise/data/allnoise_flight_data-Winter2020.csv")
data
# count
#data$tested_b <- 0
data$tested_b[data$tested == "yes"] <- 1
data
tapply(X=as.numeric(data$tested), INDEX=data$chamber, FUN=sum, na.rm=T)
as.numeric(data$tested)
as.numeric(as.factor(data$tested))
# count
data$tested_b <- 0
data$tested_b[data$tested == "yes"] <- 1
tapply(X=as.numeric(as.factor(data$tested)), INDEX=data$chamber, FUN=sum, na.rm=T)
# sum of distances
tapply(X=data$distance, INDEX=data$chamber, FUN=sum, na.rm=T)
# mean of distances
tapply(X=data$distance, INDEX=data$chamber, FUN=mean, na.rm=T)
# pwc = "Pairwise Wilcoxon test" between groups
pwc <- data %>%
dunn_test(distance ~ chamber, p.adjust.method = "bonferroni")
pwc
# pwc = "Pairwise Wilcoxon test" between groups
pwc <- data %>%
dunn_test(distance ~ chamber, p.adjust.method = "bonferroni")
pwc
pwc <- pwc %>% add_xy_position(x = "chamber")
pwc
res.kruskal <- data %>% kruskal_test(distance ~ chamber)
res.kruskal
ggboxplot(data, x = "chamber", y = "distance") +
stat_pvalue_manual(pwc, hide.ns = TRUE) +
labs(
subtitle = get_test_label(res.kruskal, detailed = TRUE),
caption = get_pwc_label(pwc)
)
ggboxplot(data, x = "chamber", y = "distance") +
stat_pvalue_manual(pwc, hide.ns = TRUE) +
labs(
subtitle = get_test_label(res.kruskal, detailed = TRUE),
caption = get_pwc_label(pwc)
)
res.kruskal <- data %>% kruskal_test(distance ~ chamber)
res.kruskal <- data %>% kruskal_test(distance ~ chamber)
res.kruskal
# pwc = "Pairwise Wilcoxon test" between groups
pwc <- data %>%
dunn_test(distance ~ chamber, p.adjust.method = "bonferroni")
pwc
pwc <- pwc %>% add_xy_position(x = "chamber")
pwc
res.kruskal <- data %>% kruskal_test(distance ~ chamber)
res.kruskal
ggboxplot(data, x = "chamber", y = "distance") +
stat_pvalue_manual(pwc, hide.ns = TRUE) +
labs(
subtitle = get_test_label(res.kruskal, detailed = TRUE),
caption = get_pwc_label(pwc)
)
?kruskal_test
data
ggplot(data, aes(x=distance, color=chamber)) +
geom_histogram(fill="white")
pwc <- data %>%
dunn_test(distance ~ chamber, p.adjust.method = "bonferroni")
pwc <- pwc %>% add_xy_position(x = "chamber")
pwc # can see differences between test groups if print pwc. None were significant.
ggplot(data, aes(chamber, distance)) +
geom_violin() +
labs(
subtitle = get_test_label(res.kruskal, detailed = TRUE),
caption = get_pwc_label(pwc)
) +
theme(legend.position="none") +
xlab("chamber") +
ylab("distance (m)") +
geom_boxplot(width=0.1) +
stat_pvalue_manual(pwc, hide.ns = TRUE)
res.kruskal
?dunn_test
# pwc = "Pairwise Wilcoxon test" between groups
pwc <- data %>%
dunn_test(distance ~ chamber, p.adjust.method = "bonferroni") %>% add_xy_position(x = "chamber")
pwc
rm(list=ls()) # list=ls() is base in this command that means you are referring to all the objects present in the workspace
# some libraries you'll need for the Kruskal-Wallis test
library(tidyverse)
library(ggpubr)
library(rstatix)
library(knitr)
library(ggplot2)
dir = "~/Desktop/git_repositories/undergrad-collabs/voltage_noise/"
setwd(dir)
knitr::opts_chunk$set(echo = TRUE)
data = read_csv("data/allnoise_flight_data-Winter2020.csv")
data
# count
data$tested_b <- 0 #initialized a column, baseline
data$tested_b[data$tested == "yes"] <- 1
tapply(X=data$tested_b, INDEX=data$chamber, FUN=sum, na.rm=T)
# sum of distances
tapply(X=data$distance, INDEX=data$chamber, FUN=sum, na.rm=T)
# mean of distances
tapply(X=data$distance, INDEX=data$chamber, FUN=mean, na.rm=T)
# count
data$tested_b <- 0 #initialized a column, baseline
data$tested_b[data$tested == "yes"] <- 1
tapply(X=data$tested_b, INDEX=data$chamber, FUN=sum, na.rm=T)
# sum of distances
tapply(X=data$distance, INDEX=data$chamber, FUN=sum, na.rm=T)
# mean of distances
tapply(X=data$distance, INDEX=data$chamber, FUN=mean, na.rm=T)
apply(X=data$tested_b, INDEX=data$chamber, FUN=sum, na.rm=T)
tapply(X=data$tested_b, INDEX=data$chamber, FUN=sum, na.rm=T)
# sum of distances
tapply(X=data$distance, INDEX=data$chamber, FUN=sum, na.rm=T)
# mean of distances
tapply(X=data$distance, INDEX=data$chamber, FUN=mean, na.rm=T)
# pwc = "Pairwise Wilcoxon test" between groups
pwc <- data %>%
dunn_test(distance ~ chamber, p.adjust.method = "bonferroni")
pwc <- pwc %>% add_xy_position(x = "chamber")
res.kruskal <- data %>% kruskal_test(distance ~ chamber)
res.kruskal
ggboxplot(data, x = "chamber", y = "distance") +
stat_pvalue_manual(pwc, hide.ns = TRUE) +
labs(
subtitle = get_test_label(res.kruskal, detailed = TRUE),
caption = get_pwc_label(pwc)
)
# pwc = "Pairwise Wilcoxon test" between groups
pwc <- data %>%
dunn_test(distance ~ chamber, p.adjust.method = "bonferroni")
pwc <- pwc %>% add_xy_position(x = "chamber")
pwc
res.kruskal <- data %>% kruskal_test(distance ~ chamber)
res.kruskal
ggboxplot(data, x = "chamber", y = "distance") +
stat_pvalue_manual(pwc, hide.ns = TRUE) +
labs(
subtitle = get_test_label(res.kruskal, detailed = TRUE),
caption = get_pwc_label(pwc)
)
pwc <- data %>%
dunn_test(distance ~ chamber, p.adjust.method = "bonferroni")
pwc <- pwc %>% add_xy_position(x = "chamber")
pwc # can see differences between test groups if print pwc. None were significant.
ggplot(data, aes(chamber, distance)) +
geom_violin() +
labs(
subtitle = get_test_label(res.kruskal, detailed = TRUE),
caption = get_pwc_label(pwc)
) +
theme(legend.position="none") +
xlab("chamber") +
ylab("distance (m)") +
geom_boxplot(width=0.1) +
stat_pvalue_manual(pwc, hide.ns = TRUE)
rm(list=ls()) # list=ls() is base in this command that means you are referring to all the objects present in the workspace
# some libraries you'll need for the Kruskal-Wallis test
library(tidyverse)
library(ggpubr)
library(rstatix)
library(knitr)
library(ggplot2)
dir = "~/Desktop/git_repositories/undergrad-collabs/voltage_noise/"
setwd(dir)
knitr::opts_chunk$set(echo = TRUE)
data = read_csv("data/allnoise_flight_data-Winter2020.csv")
data
# count
data$tested_b <- 0 #initialized a column, baseline
data$tested_b[data$tested == "yes"] <- 1
tapply(X=data$tested_b, INDEX=data$chamber, FUN=sum, na.rm=T)
# sum of distances
tapply(X=data$distance, INDEX=data$chamber, FUN=sum, na.rm=T)
# mean of distances
tapply(X=data$distance, INDEX=data$chamber, FUN=mean, na.rm=T)
# pwc = "Pairwise Wilcoxon test" between groups
pwc <- data %>%
dunn_test(distance ~ chamber, p.adjust.method = "bonferroni")
pwc <- pwc %>% add_xy_position(x = "chamber")
pwc
res.kruskal <- data %>% kruskal_test(distance ~ chamber)
res.kruskal
ggboxplot(data, x = "chamber", y = "distance") +
stat_pvalue_manual(pwc, hide.ns = TRUE) +
labs(
subtitle = get_test_label(res.kruskal, detailed = TRUE),
caption = get_pwc_label(pwc)
)
pwc <- data %>%
dunn_test(distance ~ chamber, p.adjust.method = "bonferroni")
pwc <- pwc %>% add_xy_position(x = "chamber")
pwc # can see differences between test groups if print pwc. None were significant.
ggplot(data, aes(chamber, distance)) +
geom_violin() +
labs(
subtitle = get_test_label(res.kruskal, detailed = TRUE),
caption = get_pwc_label(pwc)
) +
theme(legend.position="none") +
xlab("chamber") +
ylab("distance (m)") +
geom_boxplot(width=0.1) +
stat_pvalue_manual(pwc, hide.ns = TRUE)
